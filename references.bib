@article{krizhevsky2017imagenet,
  title     = {Imagenet classification with deep convolutional neural networks},
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal   = {Communications of the ACM},
  volume    = {60},
  number    = {6},
  pages     = {84--90},
  year      = {2017},
  publisher = {AcM New York, NY, USA}
}

@inproceedings{abadi2016tensorflow,
  title     = {$\{$TensorFlow$\}$: a system for $\{$Large-Scale$\}$ machine learning},
  author    = {Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle = {12th USENIX symposium on operating systems design and implementation (OSDI 16)},
  pages     = {265--283},
  year      = {2016}
}

@article{paszke2019pytorch,
  title   = {Pytorch: An imperative style, high-performance deep learning library},
  author  = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal = {Advances in neural information processing systems},
  volume  = {32},
  year    = {2019}
}

@inproceedings{feng2021apnn,
  title     = {Apnn-tc: Accelerating arbitrary precision neural networks on ampere gpu tensor cores},
  author    = {Feng, Boyuan and Wang, Yuke and Geng, Tong and Li, Ang and Ding, Yufei},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages     = {1--13},
  year      = {2021}
}

@article{tabernik2019deep,
  title     = {Deep learning for large-scale traffic-sign detection and recognition},
  author    = {Tabernik, Domen and Sko{\v{c}}aj, Danijel},
  journal   = {IEEE transactions on intelligent transportation systems},
  volume    = {21},
  number    = {4},
  pages     = {1427--1440},
  year      = {2019},
  publisher = {IEEE}
}

@inproceedings{nguyen2017animal,
  title        = {Animal recognition and identification with deep convolutional neural networks for automated wildlife monitoring},
  author       = {Nguyen, Hung and Maclagan, Sarah J and Nguyen, Tu Dinh and Nguyen, Thin and Flemons, Paul and Andrews, Kylie and Ritchie, Euan G and Phung, Dinh},
  booktitle    = {2017 IEEE international conference on data science and advanced Analytics (DSAA)},
  pages        = {40--49},
  year         = {2017},
  organization = {IEEE}
}

@article{onyema2021enhancement,
  title     = {Enhancement of patient facial recognition through deep learning algorithm: ConvNet},
  author    = {Onyema, Edeh Michael and Shukla, Piyush Kumar and Dalal, Surjeet and Mathur, Mayuri Neeraj and Zakariah, Mohammed and Tiwari, Basant},
  journal   = {Journal of Healthcare Engineering},
  volume    = {2021},
  year      = {2021},
  publisher = {Hindawi}
}

@inproceedings{dutta2018improving,
  title        = {Improving CNN-RNN hybrid networks for handwriting recognition},
  author       = {Dutta, Kartik and Krishnan, Praveen and Mathew, Minesh and Jawahar, CV},
  booktitle    = {2018 16th international conference on frontiers in handwriting recognition (ICFHR)},
  pages        = {80--85},
  year         = {2018},
  organization = {IEEE}
}

@article{skourt2018lung,
  title     = {Lung CT image segmentation using deep neural networks},
  author    = {Skourt, Brahim Ait and El Hassani, Abdelhamid and Majda, Aicha},
  journal   = {Procedia Computer Science},
  volume    = {127},
  pages     = {109--113},
  year      = {2018},
  publisher = {Elsevier}
}

@article{akkus2017deep,
  title     = {Deep learning for brain MRI segmentation: state of the art and future directions},
  author    = {Akkus, Zeynettin and Galimzianova, Alfiia and Hoogi, Assaf and Rubin, Daniel L and Erickson, Bradley J},
  journal   = {Journal of digital imaging},
  volume    = {30},
  number    = {4},
  pages     = {449--459},
  year      = {2017},
  publisher = {Springer}
}

@article{mohsen2018classification,
  title     = {Classification using deep learning neural networks for brain tumors},
  author    = {Mohsen, Heba and El-Dahshan, El-Sayed A and El-Horbaty, El-Sayed M and Salem, Abdel-Badeeh M},
  journal   = {Future Computing and Informatics Journal},
  volume    = {3},
  number    = {1},
  pages     = {68--71},
  year      = {2018},
  publisher = {Elsevier}
}

@article{cogan2019mapgi,
  title     = {MAPGI: Accurate identification of anatomical landmarks and diseased tissue in gastrointestinal tract using deep learning},
  author    = {Cogan, Timothy and Cogan, Maribeth and Tamil, Lakshman},
  journal   = {Computers in biology and medicine},
  volume    = {111},
  pages     = {103351},
  year      = {2019},
  publisher = {Elsevier}
}

@article{liu2020deep,
  title     = {A deep learning system for differential diagnosis of skin diseases},
  author    = {Liu, Yuan and Jain, Ayush and Eng, Clara and Way, David H and Lee, Kang and Bui, Peggy and Kanada, Kimberly and de Oliveira Marinho, Guilherme and Gallegos, Jessica and Gabriele, Sara and others},
  journal   = {Nature medicine},
  volume    = {26},
  number    = {6},
  pages     = {900--908},
  year      = {2020},
  publisher = {Nature Publishing Group}
}

@article{tanzi2020x,
  title     = {X-ray bone fracture classification using deep learning: a baseline for designing a reliable approach},
  author    = {Tanzi, Leonardo and Vezzetti, Enrico and Moreno, Rodrigo and Moos, Sandro},
  journal   = {Applied Sciences},
  volume    = {10},
  number    = {4},
  pages     = {1507},
  year      = {2020},
  publisher = {MDPI}
}

@article{ngo2017combining,
  title     = {Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance},
  author    = {Ngo, Tuan Anh and Lu, Zhi and Carneiro, Gustavo},
  journal   = {Medical image analysis},
  volume    = {35},
  pages     = {159--171},
  year      = {2017},
  publisher = {Elsevier}
}

@article{abbas2017glaucoma,
  title     = {Glaucoma-deep: detection of glaucoma eye disease on retinal fundus images using deep learning},
  author    = {Abbas, Qaisar},
  journal   = {International Journal of Advanced Computer Science and Applications},
  volume    = {8},
  number    = {6},
  year      = {2017},
  publisher = {Science and Information (SAI) Organization Limited}
}

@article{aggarwal2021diagnostic,
  title     = {Diagnostic accuracy of deep learning in medical imaging: A systematic review and meta-analysis},
  author    = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel SW and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
  journal   = {NPJ digital medicine},
  volume    = {4},
  number    = {1},
  pages     = {1--23},
  year      = {2021},
  publisher = {Nature Publishing Group}
}

@article{alexander2020intelligent,
  title     = {An intelligent future for medical imaging: a market outlook on artificial intelligence for medical imaging},
  author    = {Alexander, Alan and Jiang, Adam and Ferreira, Cara and Zurkiya, Delphine},
  journal   = {Journal of the American College of Radiology},
  volume    = {17},
  number    = {1},
  pages     = {165--170},
  year      = {2020},
  publisher = {Elsevier}
}

@article{wu2019validation,
  title   = {Validation of a deep learning mammography model in a population with low screening rates},
  author  = {Wu, Kevin and Wu, Eric and Wu, Yaping and Tan, Hongna and Sorensen, Greg and Wang, Meiyun and Lotter, Bill},
  journal = {arXiv preprint arXiv:1911.00364},
  year    = {2019}
}

@article{cogan2019rams,
  title     = {RAMS: Remote and automatic mammogram screening},
  author    = {Cogan, Timothy and Cogan, Maribeth and Tamil, Lakshman},
  journal   = {Computers in biology and medicine},
  volume    = {107},
  pages     = {18--29},
  year      = {2019},
  publisher = {Elsevier}
}

@article{sasaki2020artificial,
  title     = {Artificial intelligence for breast cancer detection in mammography: experience of use of the ScreenPoint Medical Transpara system in 310 Japanese women},
  author    = {Sasaki, Michiro and Tozaki, Mitsuhiro and Rodr{\'\i}guez-Ruiz, Alejandro and Yotsumoto, Daisuke and Ichiki, Yumi and Terawaki, Aiko and Oosako, Shunichi and Sagara, Yasuaki and Sagara, Yoshiaki},
  journal   = {Breast Cancer},
  volume    = {27},
  number    = {4},
  pages     = {642--651},
  year      = {2020},
  publisher = {Springer}
}

@article{cheddad2014area,
  title     = {Area and volumetric density estimation in processed full-field digital mammograms for risk assessment of breast cancer},
  author    = {Cheddad, Abbas and Czene, Kamila and Eriksson, Mikael and Li, Jingmei and Easton, Douglas and Hall, Per and Humphreys, Keith},
  journal   = {PloS one},
  volume    = {9},
  number    = {10},
  pages     = {e110690},
  year      = {2014},
  publisher = {Public Library of Science San Francisco, USA}
}

@article{mohamed2018deep,
  title     = {A deep learning method for classifying mammographic breast density categories},
  author    = {Mohamed, Aly A and Berg, Wendie A and Peng, Hong and Luo, Yahong and Jankowitz, Rachel C and Wu, Shandong},
  journal   = {Medical physics},
  volume    = {45},
  number    = {1},
  pages     = {314--321},
  year      = {2018},
  publisher = {Wiley Online Library}
}

@inproceedings{cogan2020deep,
  author    = {Cogan, Timothy and Tamil, Lakshman},
  booktitle = {2020 42nd Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)},
  title     = {Deep Understanding of Breast Density Classification},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1140-1143},
  doi       = {10.1109/EMBC44109.2020.9176628}
}

@article{lehman2019mammographic,
  title     = {Mammographic breast density assessment using deep learning: clinical implementation},
  author    = {Lehman, Constance D and Yala, Adam and Schuster, Tal and Dontchos, Brian and Bahl, Manisha and Swanson, Kyle and Barzilay, Regina},
  journal   = {Radiology},
  volume    = {290},
  number    = {1},
  pages     = {52--58},
  year      = {2019},
  publisher = {Radiological Society of North America}
}

@article{saffari2020fully,
  title     = {Fully automated breast density segmentation and classification using deep learning},
  author    = {Saffari, Nasibeh and Rashwan, Hatem A and Abdel-Nasser, Mohamed and Kumar Singh, Vivek and Arenas, Meritxell and Mangina, Eleni and Herrera, Blas and Puig, Domenec},
  journal   = {Diagnostics},
  volume    = {10},
  number    = {11},
  pages     = {988},
  year      = {2020},
  publisher = {MDPI}
}

@article{yala2019deep,
  title     = {A deep learning mammography-based model for improved breast cancer risk prediction},
  author    = {Yala, Adam and Lehman, Constance and Schuster, Tal and Portnoi, Tally and Barzilay, Regina},
  journal   = {Radiology},
  volume    = {292},
  number    = {1},
  pages     = {60--66},
  year      = {2019},
  publisher = {Radiological Society of North America}
}

@article{hamidinekoo2018deep,
  title     = {Deep learning in mammography and breast histology, an overview and future trends},
  author    = {Hamidinekoo, Azam and Denton, Erika and Rampun, Andrik and Honnor, Kate and Zwiggelaar, Reyer},
  journal   = {Medical image analysis},
  volume    = {47},
  pages     = {45--67},
  year      = {2018},
  publisher = {Elsevier}
}

@article{freer2015mammographic,
  title     = {Mammographic breast density: impact on breast cancer risk and implications for screening},
  author    = {Freer, Phoebe E},
  journal   = {Radiographics},
  volume    = {35},
  number    = {2},
  pages     = {302--315},
  year      = {2015},
  publisher = {Radiological Society of North America}
}

@article{noor2020can,
  title     = {Can we trust AI not to further embed racial bias and prejudice?},
  author    = {Noor, Poppy},
  journal   = {BMJ},
  volume    = {368},
  year      = {2020},
  publisher = {British Medical Journal Publishing Group}
}

@article{noseworthy2020assessing,
  title     = {Assessing and mitigating bias in medical artificial intelligence: the effects of race and ethnicity on a deep learning model for ECG analysis},
  author    = {Noseworthy, Peter A and Attia, Zachi I and Brewer, LaPrincess C and Hayes, Sharonne N and Yao, Xiaoxi and Kapa, Suraj and Friedman, Paul A and Lopez-Jimenez, Francisco},
  journal   = {Circulation: Arrhythmia and Electrophysiology},
  volume    = {13},
  number    = {3},
  pages     = {e007988},
  year      = {2020},
  publisher = {Am Heart Assoc}
}

@article{lee2017curated,
  title     = {A curated mammography data set for use in computer-aided detection and diagnosis research},
  author    = {Lee, Rebecca Sawyer and Gimenez, Francisco and Hoogi, Assaf and Miyake, Kanae Kawai and Gorovoy, Mia and Rubin, Daniel L},
  journal   = {Scientific data},
  volume    = {4},
  number    = {1},
  pages     = {1--9},
  year      = {2017},
  publisher = {Nature Publishing Group}
}

@article{moreira2012inbreast,
  title     = {Inbreast: toward a full-field digital mammographic database},
  author    = {Moreira, In{\^e}s C and Amaral, Igor and Domingues, In{\^e}s and Cardoso, Ant{\'o}nio and Cardoso, Maria Joao and Cardoso, Jaime S},
  journal   = {Academic radiology},
  volume    = {19},
  number    = {2},
  pages     = {236--248},
  year      = {2012},
  publisher = {Elsevier}
}

@article{nguyen2022vindr,
  title     = {VinDr-Mammo: A large-scale benchmark dataset for computer-aided diagnosis in full-field digital mammography},
  author    = {Nguyen, Hieu Trung and Nguyen, Ha Quy and Pham, Hieu Huy and Lam, Khanh and Le, Linh Tuan and Dao, Minh and Vu, Van},
  journal   = {medRxiv},
  year      = {2022},
  publisher = {Cold Spring Harbor Laboratory Press}
}

@article{suckling1994mammographic,
  title     = {The mammographic image analysis society digital mammogram database},
  author    = {SUCKLING J, P},
  journal   = {Digital Mammo},
  pages     = {375--386},
  year      = {1994},
  publisher = {Elsevier Sc. BV}
}

@software{kelsey_jordahl_2020_3946761,
  author    = {Kelsey Jordahl and
               Joris Van den Bossche and
               Martin Fleischmann and
               Jacob Wasserman and
               James McBride and
               Jeffrey Gerard and
               Jeff Tratner and
               Matthew Perry and
               Adrian Garcia Badaracco and
               Carson Farmer and
               Geir Arne Hjelle and
               Alan D. Snow and
               Micah Cochran and
               Sean Gillies and
               Lucas Culbertson and
               Matt Bartos and
               Nick Eubank and
               maxalbert and
               Aleksey Bilogur and
               Sergio Rey and
               Christopher Ren and
               Dani Arribas-Bel and
               Leah Wasser and
               Levi John Wolf and
               Martin Journois and
               Joshua Wilson and
               Adam Greenhall and
               Chris Holdgraf and
               Filipe and
               François Leblanc},
  title     = {geopandas/geopandas: v0.8.1},
  month     = jul,
  year      = 2020,
  publisher = {Zenodo},
  version   = {v0.8.1},
  doi       = {10.5281/zenodo.3946761},
  url       = {https://doi.org/10.5281/zenodo.3946761}
}

@article{lichter2012immigration,
  title     = {Immigration and the new racial diversity in rural America},
  author    = {Lichter, Daniel T},
  journal   = {Rural sociology},
  volume    = {77},
  number    = {1},
  pages     = {3--35},
  year      = {2012},
  publisher = {Wiley Online Library}
}

@article{simon2013collecting,
  title     = {Collecting ethnic statistics in Europe: a review},
  author    = {Simon, Patrick},
  journal   = {Accounting for Ethnic and Racial Diversity},
  pages     = {22--47},
  year      = {2013},
  publisher = {Routledge}
}

@article{belanger2010ethnic,
  title     = {Ethnic diversity and statistics in East Asia:‘Foreign brides’ surveys in Taiwan and South Korea},
  author    = {B{\'e}langer, Dani{\`e}le and Lee, Hye-Kyung and Wang, Hong-Zen},
  journal   = {Ethnic and Racial Studies},
  volume    = {33},
  number    = {6},
  pages     = {1108--1130},
  year      = {2010},
  publisher = {Taylor \& Francis}
}

@article{ho2020denoising,
  title   = {Denoising diffusion probabilistic models},
  author  = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal = {Advances in neural information processing systems},
  volume  = {33},
  pages   = {6840--6851},
  year    = {2020}
}

@article{creswell2018generative,
  title     = {Generative adversarial networks: An overview},
  author    = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A},
  journal   = {IEEE signal processing magazine},
  volume    = {35},
  number    = {1},
  pages     = {53--65},
  year      = {2018},
  publisher = {IEEE}
}

@article{badano2018evaluation,
  title     = {Evaluation of digital breast tomosynthesis as replacement of full-field digital mammography using an in silico imaging trial},
  author    = {Badano, Aldo and Graff, Christian G and Badal, Andreu and Sharma, Diksha and Zeng, Rongping and Samuelson, Frank W and Glick, Stephen J and Myers, Kyle J},
  journal   = {JAMA network open},
  volume    = {1},
  number    = {7},
  pages     = {e185474--e185474},
  year      = {2018},
  publisher = {American Medical Association}
}

@inproceedings{assran2023self,
  title     = {Self-supervised learning from images with a joint-embedding predictive architecture},
  author    = {Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {15619--15629},
  year      = {2023}
}

@article{sharma2019silico,
  title     = {In silico imaging tools from the VICTRE clinical trial},
  author    = {Sharma, Diksha and Graff, Christian G and Badal, Andreu and Zeng, Rongping and Sawant, Purva and Sengupta, Aunnasha and Dahal, Eshan and Badano, Aldo},
  journal   = {Medical physics},
  volume    = {46},
  number    = {9},
  pages     = {3924--3928},
  year      = {2019},
  publisher = {Wiley Online Library}
}

@article{lee2021identifying,
  title     = {Identifying women with mammographically-occult breast cancer leveraging GAN-simulated mammograms},
  author    = {Lee, Juhun and Nishikawa, Robert M},
  journal   = {IEEE transactions on medical imaging},
  volume    = {41},
  number    = {1},
  pages     = {225--236},
  year      = {2021},
  publisher = {IEEE}
}

@article{dosovitskiy2020vit,
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal = {ICLR},
  year    = {2021}
}

@inproceedings{navit2024,
  author    = {Dehghani, Mostafa and Mustafa, Basil and Djolonga, Josip and Heek, Jonathan and Minderer, Matthias and Caron, Mathilde and Steiner, Andreas and Puigcerver, Joan and Geirhos, Robert and Alabdulmohsin, Ibrahim and Oliver, Avital and Padlewski, Piotr and Gritsenko, Alexey A. and Lucic, Mario and Houlsby, Neil},
  title     = {Patch n' pack: NaViT, a vision transformer for any aspect ratio and resolution},
  year      = {2024},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViT marks a departure from the standard, CNN-designed, input and modelling pipeline used by most computer vision models, and represents a promising direction for ViTs.},
  booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
  articleno = {106},
  numpages  = {23},
  location  = {, New Orleans, LA, USA, },
  series    = {NIPS '23}
}

@article{hendrycks2016gaussian,
  title   = {Gaussian error linear units (gelus)},
  author  = {Hendrycks, Dan and Gimpel, Kevin},
  journal = {arXiv preprint arXiv:1606.08415},
  year    = {2016}
}

@article{shazeer2020glu,
  title   = {Glu variants improve transformer},
  author  = {Shazeer, Noam},
  journal = {arXiv preprint arXiv:2002.05202},
  year    = {2020}
}

@article{loshchilov2017decoupled,
  title   = {Decoupled weight decay regularization},
  author  = {Loshchilov, Ilya and Hutter, Frank},
  journal = {arXiv preprint arXiv:1711.05101},
  year    = {2017}
}

@article{krizhevsky2009learning,
  title     = {Learning multiple layers of features from tiny images},
  author    = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  year      = {2009},
  publisher = {Toronto, ON, Canada}
}

@inproceedings{he2022masked,
  title     = {Masked autoencoders are scalable vision learners},
  author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {16000--16009},
  year      = {2022}
}

@inproceedings{caron2021emerging,
  title     = {Emerging properties in self-supervised vision transformers},
  author    = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
  pages     = {9650--9660},
  year      = {2021}
}

@article{embed2023,
  author  = {Jeong, Jiwoong J. and Vey, Brianna L. and Bhimireddy, Ananth and Kim, Thomas and Santos, Thiago and Correa, Ramon and Dutt, Raman and Mosunjac, Marina and Oprea-Ilies, Gabriela and Smith, Geoffrey and Woo, Minjae and McAdams, Christopher R. and Newell, Mary S. and Banerjee, Imon and Gichoya, Judy and Trivedi, Hari},
  title   = {The EMory BrEast imaging Dataset (EMBED): A Racially Diverse, Granular Dataset of 3.4 Million Screening and Diagnostic Mammographic Images},
  journal = {Radiology: Artificial Intelligence},
  volume  = {5},
  number  = {1},
  pages   = {e220047},
  year    = {2023},
  doi     = {10.1148/ryai.220047},
  url     = {https://doi.org/10.1148/ryai.220047},
  eprint  = {https://doi.org/10.1148/ryai.220047},
  abstract= {Supplemental material is available for this article. Keywords: Mammography, Breast, Machine Learning © RSNA, 2023}
}

@misc{jaegle2021perceiver,
      title={Perceiver: General Perception with Iterative Attention}, 
      author={Andrew Jaegle and Felix Gimeno and Andrew Brock and Andrew Zisserman and Oriol Vinyals and Joao Carreira},
      year={2021},
      eprint={2103.03206},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.03206}, 
}

@misc{yang2023gpvit,
      title={GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation}, 
      author={Chenhongyi Yang and Jiarui Xu and Shalini De Mello and Elliot J. Crowley and Xiaolong Wang},
      year={2023},
      eprint={2212.06795},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.06795}, 
}

@misc{fan2024vitar,
      title={ViTAR: Vision Transformer with Any Resolution}, 
      author={Qihang Fan and Quanzeng You and Xiaotian Han and Yongfei Liu and Yunzhe Tao and Huaibo Huang and Ran He and Hongxia Yang},
      year={2024},
      eprint={2403.18361},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.18361}, 
}

@misc{so2022relu2,
      title={Primer: Searching for Efficient Transformers for Language Modeling}, 
      author={David R. So and Wojciech Mańke and Hanxiao Liu and Zihang Dai and Noam Shazeer and Quoc V. Le},
      year={2022},
      eprint={2109.08668},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2109.08668}, 
}

@misc{hu2021lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{dao2022flash,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.14135}, 
}

@misc{liu2022convnext,
      title={A ConvNet for the 2020s}, 
      author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
      year={2022},
      eprint={2201.03545},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.03545}, 
}

@misc{touvron2021deeper,
      title={Going deeper with Image Transformers}, 
      author={Hugo Touvron and Matthieu Cord and Alexandre Sablayrolles and Gabriel Synnaeve and Hervé Jégou},
      year={2021},
      eprint={2103.17239},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.17239}, 
}

@article{victre,
    author = {Badano, Aldo and Graff, Christian G. and Badal, Andreu and Sharma, Diksha and Zeng, Rongping and Samuelson, Frank W. and Glick, Stephen J. and Myers, Kyle J.},
    title = "{Evaluation of Digital Breast Tomosynthesis as Replacement of Full-Field Digital Mammography Using an In Silico Imaging Trial}",
    journal = {JAMA Network Open},
    volume = {1},
    number = {7},
    pages = {e185474-e185474},
    year = {2018},
    month = {11},
    abstract = "{Expensive and lengthy clinical trials can delay regulatory evaluation of innovative technologies, affecting patient access to high-quality medical products. Simulation is increasingly being used in product development but rarely in regulatory applications.To conduct a computer-simulated imaging trial evaluating digital breast tomosynthesis (DBT) as a replacement for digital mammography (DM) and to compare the results with a comparative clinical trial.The simulated Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) trial was designed to replicate a clinical trial that used human patients and radiologists. Images obtained with in silico versions of DM and DBT systems via fast Monte Carlo x-ray transport were interpreted by a computational reader detecting the presence of lesions. A total of 2986 synthetic image–based virtual patients with breast sizes and radiographic densities representative of a screening population and compressed thicknesses from 3.5 to 6 cm were generated using an analytic approach in which anatomical structures are randomly created within a predefined breast volume and compressed in the craniocaudal orientation. A positive cohort contained a digitally inserted microcalcification cluster or spiculated mass.The trial end point was the difference in area under the receiver operating characteristic curve between modalities for lesion detection. The trial was sized for an SE of 0.01 in the change in area under the curve (AUC), half the uncertainty in the comparative clinical trial.In this trial, computational readers analyzed 31 055 DM and 27 960 DBT cases from 2986 virtual patients with the following Breast Imaging Reporting and Data System densities: 286 (9.6\%) extremely dense, 1200 (40.2\%) heterogeneously dense, 1200 (40.2\%) scattered fibroglandular densities, and 300 (10.0\%) almost entirely fat. The mean (SE) change in AUC was 0.0587 (0.0062) (P \&lt; .001) in favor of DBT. The change in AUC was larger for masses (mean [SE], 0.0903 [0.008]) than for calcifications (mean [SE], 0.0268 [0.004]), which was consistent with the findings of the comparative trial (mean [SE], 0.065 [0.017] for masses and −0.047 [0.032] for calcifications).The results of the simulated VICTRE trial are consistent with the performance seen in the comparative trial. While further research is needed to assess the generalizability of these findings, in silico imaging trials represent a viable source of regulatory evidence for imaging devices.}",
    issn = {2574-3805},
    doi = {10.1001/jamanetworkopen.2018.5474},
    url = {https://doi.org/10.1001/jamanetworkopen.2018.5474},
    eprint = {https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2717000/badano\_2018\_oi\_180235.pdf},
}


@misc{laion5b,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.08402}, 
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  pages={1--62},
  year={2022}
}